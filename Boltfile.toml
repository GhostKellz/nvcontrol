# NVControl Bolt Configuration
# Modern NVIDIA control panel with containerized CLI management using Bolt runtime
project = "nvcontrol"

# Main GPU management service
[services.gpu-manager]
build = "./containers/gpu-manager"
privileged = true
gpu.nvidia = true
devices = [
    "/dev/nvidia0",
    "/dev/nvidia1",
    "/dev/nvidia2",
    "/dev/nvidia3",
    "/dev/nvidia-uvm",
    "/dev/nvidia-modeset",
    "/dev/nvidiactl"
]
volumes = [
    "/usr/lib/x86_64-linux-gnu/libnvidia-ml.so:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so:ro",
    "/sys/class/drm:/sys/class/drm:ro",
    "/proc/driver/nvidia:/proc/driver/nvidia:ro"
]
env.NVIDIA_VISIBLE_DEVICES = "all"
env.NVIDIA_DRIVER_CAPABILITIES = "all"
ports = ["3000:3000"]

# GPU monitoring and metrics service
[services.gpu-monitor]
build = "./containers/monitor"
gpu.nvidia = true
volumes = ["/proc:/host/proc:ro"]
env.HOST_PROC = "/host/proc"
env.MONITORING_INTERVAL = "5"
env.METRICS_PORT = "9090"
ports = ["8080:8080", "9090:9090"]

# Driver management service (isolated updates)
[services.driver-manager]
build = "./containers/driver-manager"
privileged = true
volumes = [
    "/lib/modules:/lib/modules:ro",
    "/usr/src:/usr/src:ro",
    "/boot:/boot:ro"
]
env.DRIVER_VERSION = "535.154.05"
env.AUTO_UPDATE = "false"

# Gaming container with Proton support
[services.gaming-proton]
build = "./containers/gaming"
gpu.nvidia = true
privileged = true
devices = [
    "/dev/nvidia0",
    "/dev/nvidia-uvm",
    "/dev/nvidia-modeset",
    "/dev/nvidiactl"
]
volumes = [
    "/tmp/.X11-unix:/tmp/.X11-unix",
    "/run/user/1000/pulse:/run/user/1000/pulse"
]
env.DISPLAY = ":0"
env.NVIDIA_VISIBLE_DEVICES = "all"
env.NVIDIA_DRIVER_CAPABILITIES = "all"
env.PROTON_VERSION = "8.0"
env.WINEDLLOVERRIDES = "mscoree,mshtml="
env.PULSE_RUNTIME_PATH = "/run/user/1000/pulse"

# Web interface for remote management
[services.web-interface]
build = "./web"
ports = ["8081:8080"]
env.API_ENDPOINT = "bolt://gpu-manager:3000"
env.MONITORING_ENDPOINT = "bolt://gpu-monitor:9090"
env.AUTH_ENABLED = "true"

# PhantomLink audio processing container
[services.phantomlink-audio]
build = "./containers/phantomlink"
gpu.nvidia = true
volumes = [
    "/run/user/1000/pulse:/run/user/1000/pulse",
    "/dev/snd:/dev/snd"
]
env.RTX_VOICE_ENABLED = "true"
env.RTX_VOICE_STRENGTH = "0.8"
env.AUDIO_DEVICE = "default"
env.SAMPLE_RATE = "48000"
ports = ["8082:8080"]

# ML Training container for GPU workloads
[services.ml-training]
build = "./containers/ml-training"
gpu.nvidia = true
env.CUDA_VISIBLE_DEVICES = "0,1"
env.NVIDIA_DRIVER_CAPABILITIES = "compute,utility"
volumes = [
    "./data:/workspace/data",
    "./models:/workspace/models"
]
ports = ["8888:8888", "6006:6006"] # Jupyter, TensorBoard

# Gaming benchmarking service
[services.gpu-benchmark]
build = "./containers/benchmark"
gpu.nvidia = true
env.BENCHMARK_DURATION = "300"
env.BENCHMARK_TESTS = "compute,graphics,memory"
env.OUTPUT_FORMAT = "json"
volumes = ["./benchmark-results:/results"]

# Container image registry service
[services.registry]
build = "./containers/registry"
ports = ["5000:5000"]
volumes = ["registry-data:/var/lib/registry"]

# High-performance gaming network with QUIC
[network]
driver = "quic"
encryption = true
subnet = "10.10.0.0/16"

# Volume definitions for persistent storage
[volumes.registry-data]
driver = "local"

[volumes.gpu-metrics]
driver = "local"

[volumes.game-saves]
driver = "local"

# Gaming configuration with GPU optimizations
[gaming]
proton_version = "8.0"
wine_version = "stable"
gpu_optimizations = true
dlss_enabled = true
raytracing_enabled = true
low_latency_mode = true

[gaming.gpu]
nvidia.device = 0
nvidia.dlss = true
nvidia.raytracing = true
nvidia.cuda = true
amd.rocm = false

[gaming.audio]
system = "pipewire"
latency = "ultra-low"
rtx_voice = true
noise_suppression = 0.8

[gaming.performance]
cpu_governor = "performance"
nice_level = -10
rt_priority = 50
memory_overcommit = false

# Development and debugging services
[services.dev-tools]
build = "./containers/dev-tools"
gpu.nvidia = true
volumes = [
    ".:/workspace",
    "/var/run/docker.sock:/var/run/docker.sock"
]
env.RUST_LOG = "debug"
env.NVIDIA_DRIVER_CAPABILITIES = "all"
ports = ["8083:8080"]

# Container profiles for different workloads
[profiles.ml-training]
gpu.memory_limit = "8Gi"
gpu.power_limit = 300
gpu.compute_mode = "exclusive"
env.CUDA_MEMORY_POOL_SIZE = "0.8"

[profiles.gaming]
gpu.memory_limit = "12Gi"
gpu.power_limit = 400
gpu.boost_clocks = true
gpu.max_performance = true

[profiles.inference]
gpu.memory_limit = "4Gi"
gpu.power_limit = 200
gpu.compute_mode = "shared"

# Security and authentication
[security]
tls_enabled = true
cert_path = "/etc/nvcontrol/certs"
auth_method = "token"
token_expiry = "24h"

# Monitoring and observability
[observability]
metrics_enabled = true
logging_level = "info"
traces_enabled = true
prometheus_endpoint = "bolt://gpu-monitor:9090"